{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of AICTE_ 2_ML Pipeline.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "jXfEGGEGC63m"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pushpambagvp/Assignment1/blob/main/Copy_of_AICTE__2_ML_Pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OqBTq6xAllB"
      },
      "source": [
        "This Notebook is created exclusively for AICTE sponsored 2-weeks FDP programme (<small> Insights into Intelligent Automation, Machine Learning and Data Science: \n",
        "Artificial Intelligence & Machine Learning </small>) by **Principal Data Scientist** <font color='darkgreen'><b>Mr. Rocky</b></font> (<small> https://linkedin.com/in/rocky-jagtiani-3b390649/ </small>)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXfEGGEGC63m"
      },
      "source": [
        "ML Process flow or ML Pipeline\n",
        "--\n",
        "![basic_ML_process_flow](https://drive.google.com/uc?id=1mf5Rpq68x9AzyHMAo6xsQ9fVNDbuI4Q3 'basic_ML_process_flow')\n",
        "\n",
        "`Recall, this is where we stopped in our first NB` <br>\n",
        "1. **Data Collection**: Collect the data that the algorithm will learn from.\n",
        "\n",
        "2. **Data Preparation**: Format and engineer the data into the optimal format, extracting important features and performing dimensionality reduction. (*dimensionality reduction means when their are too many features i.e too many columns in our dataset then we need to choose few from all*)\n",
        "\n",
        "3. **Training**: Also known as the fitting stage, this is where the Machine Learning algorithm actually learns by showing it the data that has been collected and prepared.\n",
        "\n",
        "4. **Evaluation**: Test the model to see how well it performs.\n",
        "\n",
        "5. **Tuning**: Fine tune the model to maximise it’s performance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrMzFkE8DLGr"
      },
      "source": [
        "<font color='green'> <b>\n",
        "ML Pipeline is nothing but the steps you follow to clean, pre-process the data, scale or normalise it before training and testing it. \n",
        "</b></font>\n",
        "\n",
        "**`Exprienced ML Engineers`** infact make ML pipeline rigth from Preparing data to Deploying the ML model. ( see diagram below )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgkaHV4GDgd4"
      },
      "source": [
        "![Board_ML_Pipeline](https://drive.google.com/uc?id=1zEz0CfrYofJrYqD-MjGlwj6tzgyhxjVm 'Board_ML_Pipeline')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ad0OilDnH9MB"
      },
      "source": [
        "Here we would dive into solving a end-to-end ML problem - **Student Grant Recommendation**;  ofcourse a very simple problem so that you get the feel of **`ML pipeline`.**\n",
        "<br><br>\n",
        "**`Please Note`** : Later in the `Machine Learning - Intermidate` <font color='green'><b>course</b></font> you would learn how to **`automate`** the pipelining process by using **sklearn.pipeline.Pipeline class.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P091kIpDHfi7"
      },
      "source": [
        "# Objective : Student Grant Recommendation\n",
        "\n",
        "You have historical student performance data and their grant recommendation outcomes in the form of a comma separated value file named student_records.csv. Each data sample consists of the following attributes.\n",
        "\n",
        "• Name (the student name) <br>\n",
        "• OverallGrade (overall grade obtained) <br>\n",
        "• Obedient (whether they were diligent during their course of stay) <br>\n",
        "• ResearchScore (marks obtained in their research work) <br>\n",
        "• ProjectScore (marks obtained in the project) <br>\n",
        "• Recommend (whether they got the grant recommendation) <br>\n",
        "\n",
        "Your main objective is to build a predictive model based on this data such that you can predict for any future student whether they will be recommended for the grant based on their performance attributes.\n",
        "\n",
        "`Note` : This is a <u>toy dataset</u>."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nG0WxGBJJUQp"
      },
      "source": [
        "**`Step 1: Data Retrieval`** <br>\n",
        "Here, we will leverage the pandas framework to retrieve the data from the CSV file. The following snippet shows us how to retrieve the data and view it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CkflUbrKCT2",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCkgewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwogICAgICBwZXJjZW50LnRleHRDb250ZW50ID0KICAgICAgICAgIGAke01hdGgucm91bmQoKHBvc2l0aW9uIC8gZmlsZURhdGEuYnl0ZUxlbmd0aCkgKiAxMDApfSUgZG9uZWA7CiAgICB9CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "61a2ee06-9434-4566-e3ce-6a8cc8f92719"
      },
      "source": [
        "# download the dataset from this link https://drive.google.com/open?id=1viCNZx1e3Egi7zsh72zwGjrA_W8dcpul \n",
        "\n",
        "# then upload this NB to your Colab by running the below code and selecting the .csv file. \n",
        "\n",
        "# loading the dataset into this Colab NB\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-cd8f8b6f-da34-4081-aba1-9176e1c80459\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-cd8f8b6f-da34-4081-aba1-9176e1c80459\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving student_records.csv to student_records.csv\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'student_records.csv': b'Name,OverallGrade,Obedient,ResearchScore,ProjectScore,Recommend\\nHenry,A,Y,90,85,Yes\\nJohn,C,N,85,51,Yes\\nDavid,F,N,10,17,No\\nHolmes,B,Y,75,71,No\\nMarvin,E,N,20,30,No\\nSimon,A,Y,92,79,Yes\\nRobert,B,Y,60,59,No\\nTrent,C,Y,75,33,No\\n'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyEg7WKaJnvG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "outputId": "73601186-9ba4-490d-f52a-9563513a4e66"
      },
      "source": [
        "#--get data into a DataFrame\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('student_records.csv')\n",
        "df"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>OverallGrade</th>\n",
              "      <th>Obedient</th>\n",
              "      <th>ResearchScore</th>\n",
              "      <th>ProjectScore</th>\n",
              "      <th>Recommend</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Henry</td>\n",
              "      <td>A</td>\n",
              "      <td>Y</td>\n",
              "      <td>90</td>\n",
              "      <td>85</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>John</td>\n",
              "      <td>C</td>\n",
              "      <td>N</td>\n",
              "      <td>85</td>\n",
              "      <td>51</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>David</td>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>10</td>\n",
              "      <td>17</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Holmes</td>\n",
              "      <td>B</td>\n",
              "      <td>Y</td>\n",
              "      <td>75</td>\n",
              "      <td>71</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Marvin</td>\n",
              "      <td>E</td>\n",
              "      <td>N</td>\n",
              "      <td>20</td>\n",
              "      <td>30</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Simon</td>\n",
              "      <td>A</td>\n",
              "      <td>Y</td>\n",
              "      <td>92</td>\n",
              "      <td>79</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Robert</td>\n",
              "      <td>B</td>\n",
              "      <td>Y</td>\n",
              "      <td>60</td>\n",
              "      <td>59</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Trent</td>\n",
              "      <td>C</td>\n",
              "      <td>Y</td>\n",
              "      <td>75</td>\n",
              "      <td>33</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Name OverallGrade Obedient  ResearchScore  ProjectScore Recommend\n",
              "0   Henry            A        Y             90            85       Yes\n",
              "1    John            C        N             85            51       Yes\n",
              "2   David            F        N             10            17        No\n",
              "3  Holmes            B        Y             75            71        No\n",
              "4  Marvin            E        N             20            30        No\n",
              "5   Simon            A        Y             92            79       Yes\n",
              "6  Robert            B        Y             60            59        No\n",
              "7   Trent            C        Y             75            33        No"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxP3RajlLt6M"
      },
      "source": [
        "**`Step 2: Data Preparation`**<br>\n",
        "Based on the dataset (above), we do not have any data errors or missing values, hence we will mainly focus on feature engineering and scaling in this section.\n",
        "\n",
        "<h3>If you wish see <b>some \"un-clean data\" examples</b> then watch this Video</h3> \n",
        "\n",
        "<a href=\"https://drive.google.com/open?id=1NERqIE0PnmaiMInd8BUjswQNC2T1JZsn\" download=\"Introduction_to_ML\">\n",
        "  <img src=\"https://drive.google.com/uc?id=14OOsd0HaKoMJjqu5YT5n7-HsvE6UVV7z\" alt=\"SuvenML_Intro_to_ML_video\" width=\"130\" height=\"70\">\n",
        "</a>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pZX9qjyZerJ"
      },
      "source": [
        "**`Step 3 : Feature Extraction and Engineering`** <br>\n",
        "Let’s start by extracting the existing features from the dataset and the outcomes; in separate variables.\n",
        "\n",
        "`Note 1` : Features are input variables on which the ML model would be trained. They are always represented as X.\n",
        "\n",
        "`Note 2` : The only column which is not in the set of features would be the Outcome or label. Outcome or Label when available helps the ML model to map features to outcome, thereby its `Supervised Learning`.\n",
        "\n",
        "Its always advisable to start learning ML from Supervised ML , as its easier and quick to understand the concepts.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgCQkQ1dLZLx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40ac475f-fb31-45ca-fe28-cbc8a131ccb6"
      },
      "source": [
        "#--Type your code here\n",
        "#--get features and corresponding outcomes\n",
        "feature_names = ['OverallGrade', 'Obedient', 'ResearchScore', 'ProjectScore']\n",
        "training_features = df[feature_names]\n",
        "\n",
        "outcome_name = ['Recommend']\n",
        "outcome_labels = df[outcome_name]\n",
        "\n",
        "print(training_features)\n",
        "print(\"----------------\")\n",
        "print(outcome_labels)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  OverallGrade Obedient  ResearchScore  ProjectScore\n",
            "0            A        Y             90            85\n",
            "1            C        N             85            51\n",
            "2            F        N             10            17\n",
            "3            B        Y             75            71\n",
            "4            E        N             20            30\n",
            "5            A        Y             92            79\n",
            "6            B        Y             60            59\n",
            "7            C        Y             75            33\n",
            "----------------\n",
            "  Recommend\n",
            "0       Yes\n",
            "1       Yes\n",
            "2        No\n",
            "3        No\n",
            "4        No\n",
            "5       Yes\n",
            "6        No\n",
            "7        No\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ay_qoYrbhDc7"
      },
      "source": [
        "> <font color ='green'> <b> I am sure you have understood that `Features` are what we want to observe. \n",
        "\n",
        "> `Labels` are what we want to predict.</b> </font>\n",
        "\n",
        "<h3>If you wish see <b>What are Features and Labels</b> then watch this Video</h3> \n",
        "\n",
        "<a href=\"https://drive.google.com/open?id=1Kfky3-TkJtGvJE77m2uy0VqAaD57NWQO\">\n",
        "  <img src=\"https://drive.google.com/uc?id=14OOsd0HaKoMJjqu5YT5n7-HsvE6UVV7z\" alt=\"Features and Labels_rec_in_hindhi\" width=\"130\" height=\"70\">\n",
        "</a>\n",
        "\n",
        "<small> Note : This video is recorded in hindi and kept things very simple. </small>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQpslwEYkSuO"
      },
      "source": [
        "Now that we have extracted our initial available features from the data and their corresponding outcome labels, let’s separate out our available features based on their type (**`numerical`** and **`categorical`**)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hd8RdHaok2Wx"
      },
      "source": [
        "#--list down features based on type\n",
        "numeric_feature_names = ['ResearchScore', 'ProjectScore']\n",
        "categoricial_feature_names = ['OverallGrade', 'Obedient'] "
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CoGLEAcko3hZ"
      },
      "source": [
        "To know <b>Types of Data : Categorical vs. Numerical</b> - watch this Video\n",
        "\n",
        "<a href=\"https://drive.google.com/open?id=1fGUOOYV2ash-WL6-al8FvBf9z7twT7dQ\">\n",
        "  <img src=\"https://drive.google.com/uc?id=14OOsd0HaKoMJjqu5YT5n7-HsvE6UVV7z\" alt=\"Categorical and Numerical DataTypes\" width=\"110\" height=\"60\">\n",
        "</a>\n",
        "\n",
        "<small> Credits : This video is recorded by 365 DataScience Team.</small>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSSYM65EvCEh"
      },
      "source": [
        "We will now use a `standard scalar` from `scikit-learn` to **scale** or **normalize** our two numeric scorebased attributes using the following code.\n",
        "\n",
        "`Note 1 :` **Feature Scaling** is a technique to standardize the independent features present in the data in a fixed range. It is performed during the data pre-processing.\n",
        "\n",
        "*For example , if you have `youtube_Video_counts` dataset. Some videos have very small count say 50 and some very high count say 500000. If the ML model is trained using this data, then it would be baised towards video having view_count say 500000. Thereby when we use this model to predict the count of a video it would mostly predict a high value.*\n",
        "\n",
        "`Note 2 :` Their are three types of Scaling techniques or Algo's : namely **Standard Scalar**, **Min-Max Scalar** and **Robust Scalar**.\n",
        "\n",
        "`Note 3 :` All the scaling algo's are defined in **sklearn.preprocessing** library. \n",
        "\n",
        "`Note 4 :` You would learn about each Scaling technique in a later NB. Have patience.  And Yes : **Scaling** and **Normalization** mean the same thing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqjBfpEFzGe-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51e0c116-5b43-477a-b324-588975d15919"
      },
      "source": [
        "# to suppress any unwanted warnings\n",
        "#--turn of warning messages\n",
        "pd.options.mode.chained_assignment = None  # default='warn'\n",
        "#----------------------------------------------------------------------\n",
        "\n",
        "#--scale or normalize our two numeric score-based attributes\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "ss = StandardScaler()   # we are making the object of StandardScaler\n",
        "\n",
        "# fit scaler on numeric features\n",
        "ss.fit(training_features[numeric_feature_names])  # fit method learns the range of the data\n",
        "\n",
        "# scale numeric features now\n",
        "training_features[numeric_feature_names] = ss.transform(training_features[numeric_feature_names]) \n",
        "# transform method transforms the data. See the o/p. You would see a much reduced range.  \n",
        "\n",
        "# view updated feature-set\n",
        "print(training_features)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  OverallGrade Obedient  ResearchScore  ProjectScore\n",
            "0            A        Y       0.899583      1.376650\n",
            "1            C        N       0.730648     -0.091777\n",
            "2            F        N      -1.803390     -1.560203\n",
            "3            B        Y       0.392776      0.772004\n",
            "4            E        N      -1.465519     -0.998746\n",
            "5            A        Y       0.967158      1.117516\n",
            "6            B        Y      -0.114032      0.253735\n",
            "7            C        Y       0.392776     -0.869179\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-EEOsur1ZUC"
      },
      "source": [
        "<b><font color='red'> Did u notice ? </font></b> <br>\n",
        "`Before Transformation` the range of ResearchScore was 10 to 92. <br>\n",
        "`After Transformation` the range of ResearchScore is -1.803390 to 0.967158.  So I am sure you understood that the least value 10 got scaled to -1.803390 and max value 92 got scaled to 0.967158. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBakggyE4y_N"
      },
      "source": [
        "Now that we have successfully scaled our numeric features, let’s handle our categorical features and carry out the necessary feature engineering. Here we would convert the **`Categorical Data`** into **`Numeric values`**. <font color='green'> Because the ML model do not understand String data. It only understands Numeric inputs. </font>\n",
        "\n",
        "There are many ways to do Feature Engineering over the **`Categorical Data`**. Here we would use; one of the most popular technique **One Hot encoding**.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EMXkVXV4xO2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "480b4d4b-37a1-4873-937d-0e54f2e47b3e"
      },
      "source": [
        "#--Engineering Categorical Features\n",
        "#--Engineering Categorical Features\n",
        "training_features = pd.get_dummies(training_features, columns=categoricial_feature_names)\n",
        "\n",
        "# view new engineering features, where the categorical features are coded as binary\n",
        "print(training_features)\n",
        "\n",
        "\n",
        "# We have converted our categoricial data into numeric. \n",
        "# or we can say we have done feature engineering over categorical data."
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   ResearchScore  ProjectScore  ...  Obedient_N  Obedient_Y\n",
            "0       0.899583      1.376650  ...           0           1\n",
            "1       0.730648     -0.091777  ...           1           0\n",
            "2      -1.803390     -1.560203  ...           1           0\n",
            "3       0.392776      0.772004  ...           0           1\n",
            "4      -1.465519     -0.998746  ...           1           0\n",
            "5       0.967158      1.117516  ...           0           1\n",
            "6      -0.114032      0.253735  ...           0           1\n",
            "7       0.392776     -0.869179  ...           0           1\n",
            "\n",
            "[8 rows x 9 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qR33fTTLvu4"
      },
      "source": [
        "Are u feeling confused on <b>Why to do One Hot Encoding ?</b> - watch this Video\n",
        "\n",
        "<a href=\"https://drive.google.com/open?id=11HGEF45Cz0co6ntKQ4P_N9XS8Um1Jgqc\">\n",
        "  <img src=\"https://drive.google.com/uc?id=14OOsd0HaKoMJjqu5YT5n7-HsvE6UVV7z\" alt=\"One hot encoding\" width=\"110\" height=\"60\">\n",
        "</a>\n",
        "\n",
        "<small> Credits : This video is recorded by TechDose Team.</small>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7i0iUAZMZ27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f718213e-6f22-48cb-f51f-ed1111c1e43e"
      },
      "source": [
        "#--get list of new categorical features\n",
        "categorical_engineered_features=list(set(training_features.columns)-set(numeric_feature_names))\n",
        "\n",
        "print(categorical_engineered_features)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['OverallGrade_A', 'OverallGrade_E', 'OverallGrade_F', 'OverallGrade_B', 'OverallGrade_C', 'Obedient_N', 'Obedient_Y']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gz9O0t1kMlZy"
      },
      "source": [
        "**`Step 4 : Modeling`**<br>\n",
        "We will now build a simple classification (supervised) model based on our feature set by using the logistic regression algorithm. The following code depicts how to build the supervised model.\n",
        "\n",
        "\n",
        "**Wait** before moving ahead , I am assuming that you are very clear with the **first NB** on **1_Supervised & Unsupervised ML**. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5myM355NRg9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "031b723c-b2eb-4ce6-df2e-8b61118eedbc"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression  # importing the class. \n",
        "                                                     # LogisticRegression is best suited for binary classification\n",
        "import numpy as np\n",
        "import warnings; warnings.simplefilter('ignore')  \n",
        "\n",
        "#--fit the model\n",
        "lr = LogisticRegression()  # making object of the LogisticRegression class.\n",
        "\n",
        "model = lr.fit(training_features,outcome_labels['Recommend'])\n",
        "# np.array() converts from dataframe to numeric array\n",
        "# well here we are giving 2 i/ps : features and Labels to train the ML model on what i/ps produce what o/ps.\n",
        "# so the model learns the relationship. Hence we say its got trained. \n",
        "# As we gave i/p features and o/p Labels both; thereby its called Supervised Learning \n",
        "\n",
        "\n",
        "# model is ready, it can used to predict on some real data.\n",
        "model "
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjET-8evO-oY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cefb3335-8d9d-4230-eb32-14b5252f4d62"
      },
      "source": [
        "# ok, now i am giving you some real student data, who want to know whether they would be given Research Grant or not ?\n",
        "\n",
        "new_data = pd.DataFrame([{'Name': 'Ninad', 'OverallGrade': 'F', 'Obedient': 'N', 'ResearchScore': 10, 'ProjectScore': 20},\n",
        "                  {'Name': 'Alxis', 'OverallGrade': 'B', 'Obedient': 'Y', 'ResearchScore': 78, 'ProjectScore': 80}, \n",
        "                  {'Name': 'Faiz', 'OverallGrade': 'C', 'Obedient': 'N', 'ResearchScore': 69, 'ProjectScore': 70}, \n",
        "                  {'Name': 'Sejal', 'OverallGrade': 'A', 'Obedient': 'Y', 'ResearchScore': 98, 'ProjectScore': 88},\n",
        "                  {'Name': 'Vijan', 'OverallGrade': 'E', 'Obedient': 'N', 'ResearchScore': 28, 'ProjectScore': 30}])\n",
        "\n",
        "print(new_data)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    Name OverallGrade Obedient  ResearchScore  ProjectScore\n",
            "0  Ninad            F        N             10            20\n",
            "1  Alxis            B        Y             78            80\n",
            "2   Faiz            C        N             69            70\n",
            "3  Sejal            A        Y             98            88\n",
            "4  Vijan            E        N             28            30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9o1PRlkARTMu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f057601-5a98-40b5-96b4-41f8f523dab2"
      },
      "source": [
        "# w.r.t new data\n",
        "# We will now carry out the tasks relevant to \n",
        "# data preparation—feature extraction, engineering, and scaling \n",
        "# in the following code snippet.  Same as what we did over training data.\n",
        "\n",
        "#--data preparation\n",
        "prediction_features = new_data[feature_names]\n",
        "\n",
        "#--scaling by using standardScalar object -> ss\n",
        "prediction_features[numeric_feature_names] = ss.transform(prediction_features[numeric_feature_names])\n",
        "\n",
        "#--engineering categorical variables -> using One Hot Encoding\n",
        "prediction_features = pd.get_dummies(prediction_features, columns=categoricial_feature_names)\n",
        "\n",
        "#--view feature set\n",
        "print(prediction_features)\n",
        "print(\"-----------------------------\")\n",
        "print(prediction_features.columns)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   ResearchScore  ProjectScore  ...  Obedient_N  Obedient_Y\n",
            "0      -1.803390     -1.430636  ...           1           0\n",
            "1       0.494137      1.160705  ...           0           1\n",
            "2       0.190053      0.728815  ...           1           0\n",
            "3       1.169881      1.506217  ...           0           1\n",
            "4      -1.195221     -0.998746  ...           1           0\n",
            "\n",
            "[5 rows x 9 columns]\n",
            "-----------------------------\n",
            "Index(['ResearchScore', 'ProjectScore', 'OverallGrade_A', 'OverallGrade_B',\n",
            "       'OverallGrade_C', 'OverallGrade_E', 'OverallGrade_F', 'Obedient_N',\n",
            "       'Obedient_Y'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhqIc9o0Sz_5"
      },
      "source": [
        "**Important :** We are safe, as the no. of columns in the training_features and prediction_features <font color='green'><b>are same</b></font>.\n",
        "\n",
        "**Don't worry**, *we will later come across cases where the test data or real time data on which we wish to do predictions , does not have same no. of features. In such cases we will have to add dummy feature columns. Will talk and code on this some time later.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNJrzaHWUETp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ccd5f79-8799-4abe-c3a8-c5f6bc5fdc9a"
      },
      "source": [
        "# We have our complete feature set ready for all the new students. \n",
        "# Let’s put our model to the test and get the predictions \n",
        "# with regard to grant recommendations!\n",
        "\n",
        "predictions = model.predict(prediction_features)\n",
        "\n",
        "##--display results\n",
        "new_data['Recommend'] = predictions\n",
        "print(new_data)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    Name OverallGrade Obedient  ResearchScore  ProjectScore Recommend\n",
            "0  Ninad            F        N             10            20        No\n",
            "1  Alxis            B        Y             78            80        No\n",
            "2   Faiz            C        N             69            70       Yes\n",
            "3  Sejal            A        Y             98            88       Yes\n",
            "4  Vijan            E        N             28            30        No\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fjli9wbIUxq-"
      },
      "source": [
        "<font color='green'><b>Wow !!! </b></font>\n",
        "\n",
        "You have done a great Job in this NB.\n",
        "\n",
        "Let me summarise for you : \n",
        "> You understood that applying ML to some data is a <font color='green'> well defined process called ML pipeline </font>. \n",
        "\n",
        "> **You first load data**, Like we loaded it from a .csv file. Although we could load from other sources like DataBase, web-Scrap a website , from json files or read from PDF or word doc file.\n",
        "\n",
        "> You then did **required** Pre-processing like Cleaning the data, **Scaling numeric data** and **Feature engineering on Categorical data**. Like we used <font color='green'>  Standard Scaler over Numeric data and One Hot Encoding over Categorical data.</font>\n",
        "\n",
        "> You then loaded the required class, like we loaded (i.e imported) LogisticRegression class.  <br>\n",
        "*`from sklearn.linear_model import LogisticRegression`* <br>\n",
        "Remember we would use **sklearn library** a lot. Its the most used and most popular Library in Machine learning.\n",
        "\n",
        "> Then I gave some dummy student data. You smartly applied your ML model over it to classify who would get **`Research Grant and who would not ?`**\n",
        "\n",
        "<h3><font color='green'>Trust me you are going Great !! </font></h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eQdtGylajtM"
      },
      "source": [
        "<font color='green'><b>Thank you for going through the Notebook. I am sure it was a fruitful learning exprience. </b></font>\n",
        "\n",
        "You think your **educational Institution would like to collabrate for launching a Online Professional Certificate  programme in Data Science or Machine learning** with Company Internships and final Placements , then make sure to connect with me Linkedin. ( <small> https://linkedin.com/in/rocky-jagtiani-3b390649/ </small> )\n"
      ]
    }
  ]
}